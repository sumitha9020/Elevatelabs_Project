Real-Time Sign Language Recognition Using Deep Learning
 Abstract
Communication is one of the most powerful human abilities, yet people with hearing or speech impairments often face barriers when interacting with others.
This project presents an AI-based sign language recognition system that detects and interprets hand gestures in real time and converts them into text and speech.
Using a MobileNetV2 deep learning model trained on the American Sign Language (ASL) Alphabet dataset, the system achieves high accuracy and performs robustly with live webcam input.
This work demonstrates how artificial intelligence can enhance accessibility and promote inclusive humanâ€“computer interaction.
